# -*- coding: utf-8 -*-
"""resnet_discriminator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q6uv_hIhUwg-uAOX0gCPzGwTCBlWW2_N
"""

#Run on google colab
#mount gdrive 
import os
# from google.colab import drive
# drive.mount('/content/drive')

#import libraries
import numpy as np
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
from PIL import Image
import scipy.misc

import torch
import torch.nn as nn
import torch.nn.functional as F

#Check PyTorch and GPU configuration
print("PyTorch Version %s" % torch.__version__)

n_gpu = torch.cuda.device_count() #no. of GPUs available
print("No. of GPUs = %d" % n_gpu)
print("GPU type %s" % torch.cuda.get_device_name(0))

if n_gpu >= 1:
  device = torch.device("cuda:0")
  Tensor = torch.cuda.FloatTensor
else:
  device = torch.device("cpu")
  Tensor = torch.FloatTensor

#specify the volume size
in_channels = 4
out_channels = 8

batch_size = 1
image_size = 128 #256^3 volume
num_classes = 1 #outputs a scalar

feature_map_dim = 512 #accepts input volume 128^3: otherwise change appropriately
#Define the residual block of a ResNet
class ResidualBlock(nn.Module):
    def __init__(self, in_channels=in_channels):
        super(ResidualBlock, self).__init__()

        conv_block = [  nn.Conv3d(in_channels, in_channels,  kernel_size = 3, padding = 1, padding_mode='zeros'),
                        #The first two arguments are the number of i/p and o/p channels
                        nn.InstanceNorm3d(in_channels), #Applies Instance Normalization (subtract mean, divide by var)
                        nn.ReLU(inplace=True),
                        nn.Conv3d(in_channels, in_channels,  kernel_size = 3, padding = 1, padding_mode='zeros'),
                        nn.InstanceNorm3d(in_channels)  ]

        self.conv_block = nn.Sequential(*conv_block)

    def forward(self, x):
        return F.relu(x + self.conv_block(x),inplace=True)
      
# resblock = ResidualBlock().to(device)
# test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
# test_out = resblock(test_in)

#print(test_in.size())
#print(test_out.size())

class resnet_classifier(nn.Module):
    def __init__(self, in_channels=in_channels, out_channels=out_channels, num_classes=num_classes, n_residual_blocks = 5):
        super(resnet_classifier, self).__init__()

        # Initial convolution block (takes in nxnxn image, outputs nxnxn image)         
        model = [   nn.Conv3d(in_channels, out_channels,  kernel_size = 7, padding =3, padding_mode='zeros'),  #num_out_features = 64 (basically, no. of 7x7 filters), kernel_size = 7
                    nn.InstanceNorm3d(in_channels),
                    nn.ReLU(inplace=True) ]

        in_channels=out_channels
        # Residual blocks (the input to this block is of size (n/4)x(n/4), for an actual input of size nxn)
        for _ in range(n_residual_blocks):
            model += [ResidualBlock(in_channels)]
        
        self.model = nn.Sequential(*model)
        self.avgpool = nn.AvgPool3d(kernel_size=32,stride=32,padding=0)
        self.classifier = nn.Sequential(
            nn.Linear(feature_map_dim, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, num_classes),
        )
        
    def forward(self, x):
        x1 = self.model(x)
        x2 = self.avgpool(x1)
        x3 = x2.view(x2.size(0), -1)
        return self.classifier(x3)
      
test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
classifier = resnet_classifier().to(device)
test_out = classifier(test_in)

print(test_in.size())
print(test_out.size())

