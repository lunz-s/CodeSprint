# -*- coding: utf-8 -*-
"""resnet_discriminator_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q6uv_hIhUwg-uAOX0gCPzGwTCBlWW2_N
"""

#Run on google colab
#mount gdrive 
import matplotlib.pyplot as plt
import os
from google.colab import drive
drive.mount('/content/drive')

#import libraries
import numpy as np
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
from PIL import Image
import scipy.misc

import torch
import torch.nn as nn
import torch.nn.functional as F

#Check PyTorch and GPU configuration
print("PyTorch Version %s" % torch.__version__)

n_gpu = torch.cuda.device_count() #no. of GPUs available
print("No. of GPUs = %d" % n_gpu)
print("GPU type %s" % torch.cuda.get_device_name(0))

if n_gpu >= 1:
  device = torch.device("cuda:0")
  Tensor = torch.cuda.FloatTensor
else:
  device = torch.device("cpu")
  Tensor = torch.FloatTensor

#specify the volume size
in_channels = 1
out_channels = 1

batch_size = 1
image_size = 128 #256^3 volume
num_classes = 1 #outputs a scalar

feature_map_dim = 64 #accepts input volume 128^3 with 1 channel: otherwise change appropriately
res_block_kernel_size = 3
conv_block_kernel_size = 7

n_residual_blocks = 5
n_conv_blocks = 2



#Define the residual block of a ResNet
class ResidualBlock(nn.Module):
    def __init__(self, in_channels=in_channels):
        super(ResidualBlock, self).__init__()

        conv_block = [  nn.Conv3d(in_channels, in_channels,  kernel_size = res_block_kernel_size, padding = 1, padding_mode='same'),
                        #The first two arguments are the number of i/p and o/p channels
                        nn.InstanceNorm3d(in_channels), #Applies Instance Normalization (subtract mean, divide by var)
                        nn.ReLU(inplace=True),
                        nn.Conv3d(in_channels, in_channels,  kernel_size = res_block_kernel_size, padding = 1, padding_mode='same'),
                        nn.InstanceNorm3d(in_channels)  ]

        self.conv_block = nn.Sequential(*conv_block)

    def forward(self, x):
        return F.relu(x + self.conv_block(x),inplace=True)
      
# resblock = ResidualBlock().to(device)
# test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
# test_out = resblock(test_in)

#print(test_in.size())
#print(test_out.size())

class resnet_classifier(nn.Module):
    def __init__(self, in_channels=in_channels, out_channels=out_channels, num_classes=num_classes, n_conv_blocks = n_conv_blocks, n_residual_blocks = n_residual_blocks):
        super(resnet_classifier, self).__init__()

        # Initial convolution blocks (takes in nxnxn image, outputs nxnxn image)    
        model = []
        
        for _ in range(n_conv_blocks):
          model += [   nn.Conv3d(in_channels, out_channels,  kernel_size = conv_block_kernel_size, padding =3, padding_mode='same'),  #num_out_features = 64 (basically, no. of 7x7 filters), kernel_size = 7
                      nn.InstanceNorm3d(in_channels),
                      nn.ReLU(inplace=True) ]

        in_channels=out_channels
        # Residual blocks (the input to this block is of size (n/4)x(n/4), for an actual input of size nxn)
        for _ in range(n_residual_blocks):
            model += [ResidualBlock(in_channels)]
        
        self.model = nn.Sequential(*model)
        self.avgpool = nn.AvgPool3d(kernel_size=32,stride=32,padding=0)
        self.classifier = nn.Sequential(
            nn.Linear(feature_map_dim, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, num_classes),
        )
        
        self.fov = n_conv_blocks*conv_block_kernel_size + n_residual_blocks*(res_block_kernel_size-1)
    def forward(self, x):
        x1 = self.model(x)
        x2 = self.avgpool(x1)
        x3 = x2.view(x2.size(0), -1)
        return self.classifier(x3)
      
test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
classifier = resnet_classifier().to(device)
test_out = classifier(test_in)

print(test_in.size())
print(test_out.size())
#print('FOV = %d'%fov)

#custom dataset class
datapath = '/content/drive/My Drive/KTH_postdoc_work/research_ideas/code_sprint_CWI_June2-7_2019/synthetic_data/'
import glob
from torch.utils.data import Dataset
import os
import random

class ImageDataset(Dataset):
    def __init__(self, root, transforms_= None, unaligned = True, mode = 'train'):
        self.transform = transforms.Compose(transforms_)
        self.unaligned = unaligned

        self.files_A = sorted(glob.glob(os.path.join(root, '%s/GT' % mode) + '/*.*'))
        self.files_B = sorted(glob.glob(os.path.join(root, '%s/FDK' % mode) + '/*.*'))

    def __getitem__(self, index):
        item_A = np.load(self.files_A[index % len(self.files_A)])
        item_B = np.load(self.files_B[index % len(self.files_B)])

        return {'true': item_A, 'fdk': item_B}

    def __len__(self):
        return max(len(self.files_A), len(self.files_B))

#Dataset loader
transforms_ = [ 
                #transforms.Resize(int(opt["image_size"]), Image.BICUBIC), 
                #transforms.RandomCrop(opt["image_size"]), 
                #transforms.RandomHorizontalFlip(),
                #transforms.ToPILImage(),
                transforms.ToTensor(),
                #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) 
              ]
#load training data
dataloader = DataLoader(ImageDataset(datapath, transforms_=transforms_, unaligned=False), batch_size = 1, shuffle = False, num_workers = 1)

from torch.autograd import Variable
import torch.autograd as autograd
#compute the gradient penalty term to train WGAN
def compute_gradient_penalty(discriminator, real_samples, fake_samples):
    """Calculates the gradient penalty loss for WGAN"""
    # Random weight term for interpolation between real and fake samples
    #alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))
    alpha = Tensor(np.random.random(1))
    # Get random interpolation between real and fake samples
    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
    validity = classifier(interpolates)
    fake = Variable(Tensor(np.ones(validity.shape)), requires_grad=False)
    # Get gradient w.r.t. interpolates
    gradients = autograd.grad(outputs=validity, inputs=interpolates,
                              grad_outputs=fake, create_graph=True, retain_graph=True,
                              only_inputs=True)[0]
    gradients = gradients.view(gradients.size(0), -1)
    grad = F.relu(gradients)
    gradient_penalty = (grad**2).mean()
    
    #gradient_penalty = (torch.max((gradients.norm(2, dim=1) - 1),0) ** 2).mean()
    return gradient_penalty

#set the optimizer
optimizer = torch.optim.Adam(classifier.parameters(),lr = 1e-5, betas = (0.5, 0.9))

#main training loop
n_epochs = 10
total_loss = 0
disp_int = 5

for epoch in np.arange(n_epochs):
  for i, batch in enumerate(dataloader):
    true = batch["true"].type(Tensor)
    fdk = batch["fdk"].type(Tensor)
    
    #construct 5D tensors: batch_size x n_channels x height x width x depth
    true = torch.unsqueeze(true, dim=0)
    true = F.interpolate(true, size=(image_size,image_size,image_size), mode='trilinear') #sample drawn from Pr
    
    fdk = torch.unsqueeze(fdk, dim=0)
    fdk = F.interpolate(fdk, size=(image_size,image_size,image_size), mode='trilinear') #sample drawn from Pn
    
    grad_loss = compute_gradient_penalty(classifier, true.data, fdk.data) 
    loss = classifier(true) - classifier(fdk) + 10*grad_loss
    
    optimizer.zero_grad()
    loss.backward(retain_graph=True)
    optimizer.step()
    
    total_loss += loss.item()
    
    if(i % disp_int == disp_int-1):
      print('epoch:[%d/%d]\t mini-batch:[%d/%d]\t avg_loss: %.4f\n'% (epoch + 1, n_epochs, i, len(dataloader),total_loss/disp_int))
      total_loss = 0
   
#     print(true.size())
#     print(fdk.size())

#debug
real_samples = torch.randn(2,in_channels,image_size,image_size,image_size).to(device)
fake_samples = torch.randn(2,in_channels,image_size,image_size,image_size).to(device)

#alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))
alpha = Tensor(np.random.random(1))
interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
validity = classifier(interpolates)
fake = Variable(Tensor(np.ones(validity.shape)), requires_grad=False)

out = classifier(real_samples)
print(out.size())
gradients = autograd.grad(outputs=validity, inputs=interpolates,
                              grad_outputs=fake, create_graph=True, retain_graph=True,
                              only_inputs=True)[0]

gradients = gradients.view(gradients.size(0), -1)
gradient_penalty = (F.relu((gradients.norm(2, dim=1) - 1),0) ** 2).mean()
print(gradient_penalty)

out = ((F.relu((gradients.norm(2, dim=1) - 1)))**2).mean()
print(out)

torch.max()