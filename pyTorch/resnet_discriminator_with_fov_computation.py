# -*- coding: utf-8 -*-
"""resnet_discriminator_with_fov_computation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1So9qLkcC5VnS19_U6BMAH0aYNJ2D_0SH
"""

#Run on google colab
#mount gdrive 
import matplotlib.pyplot as plt
import os
from google.colab import drive
drive.mount('/content/drive')

#import libraries
import numpy as np
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
from PIL import Image
import scipy.misc

import torch
import torch.nn as nn
import torch.nn.functional as F

#Check PyTorch and GPU configuration
print("PyTorch Version %s" % torch.__version__)

n_gpu = torch.cuda.device_count() #no. of GPUs available
print("No. of GPUs = %d" % n_gpu)
print("GPU type %s" % torch.cuda.get_device_name(0))

if n_gpu >= 1:
  device = torch.device("cuda:0")
  Tensor = torch.cuda.FloatTensor
else:
  device = torch.device("cpu")
  Tensor = torch.FloatTensor

#specify the volume size
in_channels = 2
out_channels = 2

batch_size = 1
image_size = 128 #256^3 volume
num_classes = 1 #outputs a scalar

feature_map_dim = 128 #accepts input volume 128^3: otherwise change appropriately
res_block_kernel_size = 3
conv_block_kernel_size = 7
avg_pool_kernel_size = 32

n_residual_blocks = 5
n_conv_blocks = 2



#Define the residual block of a ResNet
class ResidualBlock(nn.Module):
    def __init__(self, in_channels=in_channels):
        super(ResidualBlock, self).__init__()

        conv_block = [  nn.Conv3d(in_channels, in_channels,  kernel_size = res_block_kernel_size, padding = 1, padding_mode='same'),
                        #The first two arguments are the number of i/p and o/p channels
                        nn.InstanceNorm3d(in_channels), #Applies Instance Normalization (subtract mean, divide by var)
                        nn.ReLU(inplace=True),
                        nn.Conv3d(in_channels, in_channels,  kernel_size = res_block_kernel_size, padding = 1, padding_mode='same'),
                        nn.InstanceNorm3d(in_channels)  ]

        self.conv_block = nn.Sequential(*conv_block)

    def forward(self, x):
        return F.relu(x + self.conv_block(x),inplace=True)
      
# resblock = ResidualBlock().to(device)
# test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
# test_out = resblock(test_in)

#print(test_in.size())
#print(test_out.size())

class resnet_classifier(nn.Module):
    def __init__(self, in_channels=in_channels, out_channels=out_channels, num_classes=num_classes, n_conv_blocks = n_conv_blocks, n_residual_blocks = n_residual_blocks):
        super(resnet_classifier, self).__init__()

        # Initial convolution blocks (takes in nxnxn image, outputs nxnxn image)    
        model = []
        
        for _ in range(n_conv_blocks):
          model += [   nn.Conv3d(in_channels, out_channels,  kernel_size = conv_block_kernel_size, padding =3, padding_mode='same'),  #num_out_features = 64 (basically, no. of 7x7 filters), kernel_size = 7
                      nn.InstanceNorm3d(in_channels),
                      nn.ReLU(inplace=True) ]

        in_channels=out_channels
        # Residual blocks (the input to this block is of size (n/4)x(n/4), for an actual input of size nxn)
        for _ in range(n_residual_blocks):
            model += [ResidualBlock(in_channels)]
        
        self.model = nn.Sequential(*model)
        self.avgpool = nn.AvgPool3d(kernel_size=avg_pool_kernel_size,stride=avg_pool_kernel_size,padding=0)
        self.classifier = nn.Sequential(
            nn.Linear(feature_map_dim, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, num_classes),
        )
        
        self.fov = n_conv_blocks*(conv_block_kernel_size-1) + n_residual_blocks*(res_block_kernel_size-1) + avg_pool_kernel_size
    def forward(self, x):
        x1 = self.model(x)
        x2 = self.avgpool(x1)
        x3 = x2.view(x2.size(0), -1)
        return self.classifier(x3), self.fov
      
test_in = torch.randn(batch_size,in_channels,image_size,image_size,image_size).to(device)
classifier = resnet_classifier().to(device)
test_out, fov = classifier(test_in)

print(test_in.size())
print(test_out.size())
print('one-sided FOV = %d'%np.floor(fov/2))

